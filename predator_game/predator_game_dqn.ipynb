{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "style.use('ggplot')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Cube:\n",
    "    def __init__(self, size): # 随机初始化位置坐标\n",
    "        self.size = size\n",
    "        self.x = np.random.randint(0, self.size-1)\n",
    "        self.y = np.random.randint(0, self.size-1)\n",
    "    def __str__(self):\n",
    "        return f'{self.x},{self.y}'\n",
    "    def __sub__(self, other):\n",
    "        return (self.x-other.x,self.y- other.y)\n",
    "    def __eq__(self, other):\n",
    "        return self.x == other.x and self.y == other.y\n",
    "    def action(self,choise):\n",
    "        if choise == 0:\n",
    "            self.move(x=1,y=1)\n",
    "        elif choise == 1:\n",
    "            self.move(x=-1, y=1)\n",
    "        elif choise == 2:\n",
    "            self.move(x=1, y=-1)\n",
    "        elif choise == 3:\n",
    "            self.move(x=-1, y=-1)\n",
    "        elif choise == 4:\n",
    "            self.move(x=0, y=1)\n",
    "        elif choise == 5:\n",
    "            self.move(x=0, y=-1)\n",
    "        elif choise == 6:\n",
    "            self.move(x=1, y=0)\n",
    "        elif choise == 7:\n",
    "            self.move(x=-1, y=0)\n",
    "        elif choise == 8:\n",
    "            self.move(x=0, y=0)\n",
    "    def move(self,x=False, y=False):\n",
    "        if not x:\n",
    "            self.x += np.random.randint(-1, 2)\n",
    "        else:\n",
    "            self.x += x\n",
    "        if not y:\n",
    "            self.y += np.random.randint(-1, 2)\n",
    "        else:\n",
    "            self.y += y\n",
    "\n",
    "        if self.x< 0:\n",
    "            self.x = 0\n",
    "        if self.x> self.size -1:\n",
    "            self.x = self.size-1\n",
    "        if self.y< 0:\n",
    "            self.y = 0\n",
    "        if self.y> self.size -1:\n",
    "            self.y = self.size-1\n",
    "\n",
    "class envCube:\n",
    "    SIZE = 10\n",
    "    # OBSERVATION_SPACE_VALUES = (SIZE,SIZE,3)\n",
    "    OBSERVATION_SPACE_VALUES = (4,)\n",
    "    ACTION_SPACE_VALUES = 9\n",
    "    RETURN_IMAGE = False     # 考虑返回值是否图像\n",
    "\n",
    "    FOOD_REWARD = 25  # agent获得食物的奖励\n",
    "    ENEMY_PENALITY = -300  # 遇上对手的惩罚\n",
    "    MOVE_PENALITY = -1  # 每移动一步的惩罚\n",
    "\n",
    "    # 设定三个部分的颜色分别是蓝、绿、红\n",
    "    d = {1: (255, 0, 0),  # blue\n",
    "         2: (0, 255, 0),  # green\n",
    "         3: (0, 0, 255)}  # red\n",
    "    PLAYER_N = 1\n",
    "    FOOD_N = 2\n",
    "    ENEMY_N = 3\n",
    "\n",
    "    # 环境重置\n",
    "    def reset(self):\n",
    "        self.player = Cube(self.SIZE)\n",
    "        self.food = Cube(self.SIZE)\n",
    "        self.enemy = Cube(self.SIZE)\n",
    "        # 如果玩家和食物初始位置相同，重置食物的位置，直到位置不同\n",
    "        while self.player == self.food:\n",
    "            self.food = Cube(self.SIZE)\n",
    "        # 如果敌人和玩家或食物的初始位置相同，重置敌人的位置，直到位置不同\n",
    "        while self.player == self.enemy or self.food == self.enemy:\n",
    "            self.enemy = Cube(self.SIZE)\n",
    "        # 判断观测是图像和数字\n",
    "        if self.RETURN_IMAGE:\n",
    "            observation = np.array(self.get_image())\n",
    "        else:\n",
    "            observation = (self.player - self.food)+(self.player - self.enemy)\n",
    "\n",
    "        self.episode_step = 0\n",
    "\n",
    "        return observation\n",
    "\n",
    "    def step(self,action):\n",
    "        self.episode_step +=1\n",
    "        self.player.action(action)\n",
    "        self.enemy.move()\n",
    "        self.food.move()\n",
    "        # 判断观测是图像和数字\n",
    "        if self.RETURN_IMAGE:\n",
    "            new_observation = np.array(self.get_image())\n",
    "        else:\n",
    "            new_observation = (self.player - self.food) + (self.player - self.enemy)\n",
    "\n",
    "        # 奖励\n",
    "        if self.player == self.food:\n",
    "            reward = self.FOOD_REWARD\n",
    "        elif self.player == self.enemy:\n",
    "            reward = self.ENEMY_PENALITY\n",
    "        else:\n",
    "            reward = self.MOVE_PENALITY\n",
    "\n",
    "        done = False\n",
    "\n",
    "        if self.player == self.food or self.player == self.enemy or self.episode_step >=200:\n",
    "            done = True\n",
    "\n",
    "        return new_observation,reward,done,{}\n",
    "\n",
    "    def render(self,mode='human'):\n",
    "        img = self.get_image()\n",
    "        img = img.resize((800, 800))\n",
    "        cv2.imshow('Predator',np.array(img))\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    def get_image(self):\n",
    "        env = np.zeros((self.SIZE, self.SIZE, 3), dtype=np.uint8)\n",
    "        env[self.food.x][self.food.y] = self.d[self.FOOD_N]\n",
    "        env[self.player.x][self.player.y] = self.d[self.PLAYER_N]\n",
    "        env[self.enemy.x][self.enemy.y] = self.d[self.ENEMY_N]\n",
    "        img = Image.fromarray(env, 'RGB')\n",
    "        return img\n",
    "\n",
    "    def get_qtable(self,q_table_name=None):\n",
    "        # 初始化Q表格\n",
    "        if q_table_name is None:  # 如果没有表格提供，就随机初始化一个Q表格\n",
    "            q_table = {}\n",
    "            for x1 in range(-self.SIZE + 1, self.SIZE):\n",
    "                for y1 in range(-self.SIZE + 1, self.SIZE):\n",
    "                    for x2 in range(-self.SIZE + 1, self.SIZE):\n",
    "                        for y2 in range(-self.SIZE + 1, self.SIZE):\n",
    "                            q_table[(x1, y1, x2, y2)] = [np.random.randint(-5, 0) for i in range(self.ACTION_SPACE_VALUES)]\n",
    "        else:  # 提供了，就使用提供的Q表格\n",
    "            with open(q_table_name, 'rb') as f:\n",
    "                q_table = pickle.load(f)\n",
    "        return q_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_model(status,nb_actions):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(1,) +status))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(nb_actions, activation='linear'))\n",
    "    return model\n",
    "model = build_model(envCube.OBSERVATION_SPACE_VALUES, envCube.ACTION_SPACE_VALUES)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_agent(model,nb_actions):\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    policy = BoltzmannQPolicy()\n",
    "    dqn = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=2,\n",
    "                   target_model_update=1e-2, policy=policy)\n",
    "    dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
    "    return dqn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env = envCube()\n",
    "dqn = build_agent(model,envCube.ACTION_SPACE_VALUES)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "dqn.fit(env, nb_steps=100000, visualize=False, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# After training is done, we save the final weights.\n",
    "dqn.save_weights('dqn_weights.h5f', overwrite=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dqn.load_weights('dqn_weights.h5f')\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "dqn.test(env, nb_episodes=5, visualize=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}