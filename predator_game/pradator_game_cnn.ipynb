{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.78    |\n",
      "|    explained_variance | 0.00284  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -0.0538  |\n",
      "|    value_loss         | 0.0465   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.6e+03  |\n",
      "|    ep_rew_mean        | -21      |\n",
      "| time/                 |          |\n",
      "|    fps                | 127      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 31       |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.77    |\n",
      "|    explained_variance | 0.00313  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.23    |\n",
      "|    value_loss         | 0.138    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.78e+03 |\n",
      "|    ep_rew_mean        | -20.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.78    |\n",
      "|    explained_variance | 0.0366   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | -0.1     |\n",
      "|    value_loss         | 0.0887   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.66e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.78    |\n",
      "|    explained_variance | 0.0378   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.0512   |\n",
      "|    value_loss         | 0.00106  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.66e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 122      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.78    |\n",
      "|    explained_variance | -0.00392 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -0.338   |\n",
      "|    value_loss         | 0.222    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.67e+03 |\n",
      "|    ep_rew_mean        | -20.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 121      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 98       |\n",
      "|    total_timesteps    | 12000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.7     |\n",
      "|    explained_variance | 0.042    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.306   |\n",
      "|    value_loss         | 0.22     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.67e+03 |\n",
      "|    ep_rew_mean        | -20.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.78    |\n",
      "|    explained_variance | 0.349    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.177   |\n",
      "|    value_loss         | 0.0864   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.71e+03 |\n",
      "|    ep_rew_mean        | -20.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 123      |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 129      |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.79    |\n",
      "|    explained_variance | -0.226   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.185   |\n",
      "|    value_loss         | 0.0992   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.69e+03 |\n",
      "|    ep_rew_mean        | -20.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 144      |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.7     |\n",
      "|    explained_variance | 0.811    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 0.017    |\n",
      "|    value_loss         | 0.0209   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.68e+03 |\n",
      "|    ep_rew_mean        | -20.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 124      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 160      |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.67    |\n",
      "|    explained_variance | 0.598    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 0.0285   |\n",
      "|    value_loss         | 0.00719  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.63e+03 |\n",
      "|    ep_rew_mean        | -20.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 175      |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.29    |\n",
      "|    explained_variance | 0.193    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.076    |\n",
      "|    value_loss         | 0.126    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 3.6e+03  |\n",
      "|    ep_rew_mean        | -20.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 125      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 191      |\n",
      "|    total_timesteps    | 24000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.899   |\n",
      "|    explained_variance | 0.857    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | -0.0562  |\n",
      "|    value_loss         | 0.013    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 17>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     17\u001B[0m action, _states \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(obs)\n\u001B[0;32m     18\u001B[0m obs, rewards, dones, info \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mstep(action)\n\u001B[1;32m---> 19\u001B[0m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python39\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:281\u001B[0m, in \u001B[0;36mVecEnvWrapper.render\u001B[1;34m(self, mode)\u001B[0m\n\u001B[0;32m    280\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrender\u001B[39m(\u001B[38;5;28mself\u001B[39m, mode: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[np\u001B[38;5;241m.\u001B[39mndarray]:\n\u001B[1;32m--> 281\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvenv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python39\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:89\u001B[0m, in \u001B[0;36mDummyVecEnv.render\u001B[1;34m(self, mode)\u001B[0m\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menvs[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mrender(mode\u001B[38;5;241m=\u001B[39mmode)\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 89\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python39\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:183\u001B[0m, in \u001B[0;36mVecEnv.render\u001B[1;34m(self, mode)\u001B[0m\n\u001B[0;32m    180\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[0;32m    182\u001B[0m \u001B[38;5;66;03m# Create a big image by tiling images from subprocesses\u001B[39;00m\n\u001B[1;32m--> 183\u001B[0m bigimg \u001B[38;5;241m=\u001B[39m \u001B[43mtile_images\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimgs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    185\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcv2\u001B[39;00m  \u001B[38;5;66;03m# pytype:disable=import-error\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python39\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:37\u001B[0m, in \u001B[0;36mtile_images\u001B[1;34m(img_nhwc)\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# new_width was named W before\u001B[39;00m\n\u001B[0;32m     36\u001B[0m new_width \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(np\u001B[38;5;241m.\u001B[39mceil(\u001B[38;5;28mfloat\u001B[39m(n_images) \u001B[38;5;241m/\u001B[39m new_height))\n\u001B[1;32m---> 37\u001B[0m img_nhwc \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mimg_nhwc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mimg_nhwc\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mn_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_height\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnew_width\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# img_HWhwc\u001B[39;00m\n\u001B[0;32m     39\u001B[0m out_image \u001B[38;5;241m=\u001B[39m img_nhwc\u001B[38;5;241m.\u001B[39mreshape((new_height, new_width, height, width, n_channels))\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3 import A2C"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# There already exists an environment generator\n",
    "# that will make and wrap atari environments correctly.\n",
    "# Here we are also multi-worker training (n_envs=4 => 4 environments)\n",
    "env = make_atari_env('PongNoFrameskip-v4', n_envs=4, seed=0)\n",
    "# Frame-stacking with 4 frames\n",
    "env = VecFrameStack(env, n_stack=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = A2C('CnnPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=25_000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-dae1cc48",
   "language": "python",
   "display_name": "PyCharm (reinforcement_learning)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}